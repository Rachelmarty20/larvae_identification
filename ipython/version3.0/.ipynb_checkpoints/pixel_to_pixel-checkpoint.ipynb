{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2759a3fa90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import mahotas as mh\n",
    "from wand.image import Image as WImage\n",
    "from wand.display import display\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import Image\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # 10 x 8 inches\n",
    "plt.gray()\n",
    "import seaborn as sns\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import images with appropriate structure\n",
    "2. Build Layers\n",
    "3. Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://cs231n.github.io/convolutional-networks/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://deeplearning.net/software/theano/tutorial/conv_arithmetic.html#transposed-convolution-arithmetic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###Import images with appropriate structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Might need to build a baby library of examples? These would be a slightly larger size than before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "species = 'cfellah'\n",
    "size = 100\n",
    "directory = '/cellar/users/ramarty/Data/ants/version3.0/training/{0}/{1}'.format(species, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[91, 90, 93, ..., 91, 91, 90],\n",
       "       [79, 77, 78, ..., 75, 77, 77],\n",
       "       [76, 78, 78, ..., 77, 77, 77],\n",
       "       ..., \n",
       "       [74, 73, 74, ..., 74, 76, 75],\n",
       "       [72, 71, 73, ..., 75, 76, 75],\n",
       "       [72, 71, 72, ..., 75, 76, 82]], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# image\n",
    "mh.imread('{0}/images/{1}.pgm'.format(directory, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ..., \n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target\n",
    "np.load('{0}/targets/{1}.npy'.format(directory, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_features(number_of_images):\n",
    "    features = []\n",
    "    for i in range(number_of_images):\n",
    "        features.append(mh.imread('{0}/images/{1}.pgm'.format(directory, i)))\n",
    "    return np.array(features)\n",
    "def get_targets(number_of_targets):\n",
    "    targets = []\n",
    "    for i in range(number_of_targets):\n",
    "        targets.append(np.load('{0}/targets/{1}.npy'.format(directory, i)))\n",
    "    return np.array(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = get_features(4000)\n",
    "y = get_targets(4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into training and test - maybe use a dictionary like the example?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = [(X_train, y_train),  (X_test, y_test)]\n",
    "subsets = ['train', 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = {}\n",
    "for (subset_data, subset_labels), subset_name in zip(data, subsets):\n",
    "    # The data is provided in the shape (n_examples, 784)\n",
    "    # where 784 = width*height = 28*28\n",
    "    # We need to reshape for convolutional layer shape conventions - explained below!\n",
    "    subset_data = subset_data.reshape(\n",
    "    (subset_data.shape[0], 1, 100, 100))\n",
    "    dataset[subset_name] = {\n",
    "    # We need to use data matrices of dtype theano.config.floatX\n",
    "    'X': subset_data.astype(theano.config.floatX),\n",
    "    # Labels are integers\n",
    "    'y': subset_labels.astype(theano.config.floatX)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###Build layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# input\n",
    "input_shape = dataset['train']['X'][0].shape\n",
    "# the first element is the batch size\n",
    "l_in = lasagne.layers.InputLayer(\n",
    "    shape=(None, input_shape[0], input_shape[1], input_shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 1, 100, 100)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_in.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convolution + pooling\n",
    "l_conv = lasagne.layers.Conv2DLayer(\n",
    "     l_in,\n",
    "     # Here, we set the number of filters and their size.\n",
    "     num_filters=50, filter_size=(5, 5),\n",
    "     # lasagne.nonlinearities.rectify is the common ReLU nonlinearity\n",
    "     nonlinearity=lasagne.nonlinearities.rectify,\n",
    "     # Use He et. al.'s initialization\n",
    "     W=lasagne.init.HeNormal(gain='relu'))\n",
    "    # Other arguments: Convolution type (full, same, or valid) and stride\n",
    "# Here, we do 2x2 max pooling. The max pooling layer also supports striding\n",
    "#l_pool1 = lasagne.layers.MaxPool2DLayer(l_conv1, pool_size=(2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 1, 100, 100)\n",
      "(None, 50, 96, 96)\n"
     ]
    }
   ],
   "source": [
    "print l_conv.input_shape\n",
    "print l_conv.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Dense layer - NINLayer??\\nl_nin1 = lasagne.layers.NINLayer(\\n    l_pool1,\\n    num_uits=5, # No idea what I am doing!!\\n    nonlinearity=lasagne.nonlinearities.rectify)\\n'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Dense layer - NINLayer??\n",
    "l_nin1 = lasagne.layers.NINLayer(\n",
    "    l_pool1,\n",
    "    num_uits=5, # No idea what I am doing!!\n",
    "    nonlinearity=lasagne.nonlinearities.rectify)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Upscale? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TransposedConv2DLayer (also known as fractionally strided convolutions)\n",
    "# is this different after the pooling? Do I have to do an unpooling step???\n",
    "l_deconv = lasagne.layers.TransposedConv2DLayer(l_conv, num_filters=l_conv.input_shape[1], \n",
    "                                                 filter_size=l_conv.filter_size,\n",
    "                                                 nonlinearity=lasagne.nonlinearities.rectify)\n",
    "\n",
    "#Upscale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 50, 96, 96)\n",
      "(None, 1, 100, 100)\n"
     ]
    }
   ],
   "source": [
    "print l_deconv.input_shape\n",
    "print l_deconv.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Output\n",
    "l_output = lasagne.layers.NINLayer(\n",
    "     l_deconv,\n",
    "     # The number of units in the softmas output layer is the number of classes.\n",
    "     num_units=1,\n",
    "     nonlinearity=lasagne.nonlinearities.linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 1, 100, 100)\n",
      "(None, 1, 100, 100)\n"
     ]
    }
   ],
   "source": [
    "print l_output.input_shape\n",
    "print l_output.output_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = lasagne.layers.get_output(l_output)\n",
    "targets = T.tensor3('true_output') # unsure if this is right\n",
    "loss = lasagne.objectives.squared_error(predictions, targets)\n",
    "loss = lasagne.objectives.aggregate(loss, mode='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_params = lasagne.layers.get_all_params(l_output, trainable=True)\n",
    "updates = lasagne.updates.sgd(loss, all_params, learning_rate=1)\n",
    "train = theano.function([l_in.input_var, targets], loss, updates=updates, allow_input_downcast=True, name='Training')\n",
    "get_output = theano.function([l_in.input_var], predictions, name='get_output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_output = lasagne.layers.get_output(l_output, deterministic=True)\n",
    "predict_fn = theano.function([l_in.input_var], T.argmax(get_output, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Test functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "Epoch 1 validation accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Now, let's train it! We'll chop the training data into mini-batches,\n",
    "# and compute the validation accuracy every epoch.\n",
    "BATCH_SIZE = 100\n",
    "N_EPOCHS = 1 #10\n",
    "# Keep track of which batch we're training with\n",
    "batch_idx = 0\n",
    "# Keep track of which epoch we're on\n",
    "epoch = 0\n",
    "while epoch < N_EPOCHS:\n",
    "    # Extract the training data/label batch and update the parameters with it\n",
    "    train(dataset['train']['X'][batch_idx:batch_idx + BATCH_SIZE],\n",
    "    dataset['train']['y'][batch_idx:batch_idx + BATCH_SIZE])\n",
    "    batch_idx += BATCH_SIZE\n",
    "    # Once we've trained on the entire training set...\n",
    "    print batch_idx\n",
    "    if batch_idx >= 100: #dataset['train']['X'].shape[0]:\n",
    "        # Reset the batch index\n",
    "        batch_idx = 0\n",
    "        # Update the number of epochs trained\n",
    "        epoch += 1\n",
    "        # Compute the network's on the validation data\n",
    "        #val_output = get_output(dataset['valid']['X'])\n",
    "        # The predicted class is just the index of the largest probability in the output\n",
    "        #val_predictions = np.argmax(val_output, axis=1)\n",
    "        val_predictions = get_output(dataset['test']['X'])\n",
    "        # The accuracy is the average number of correct predictions\n",
    "        # TODO: this line doesn't do what we want... \n",
    "        accuracy = np.mean(val_predictions == dataset['test']['y'])\n",
    "        print(\"Epoch {} validation accuracy: {}\".format(epoch, accuracy))\n",
    "        # want to print precision and recall here instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test']['y'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.91375195, -0.91375195, -0.91375194, ..., -0.91375195,\n",
       "        -0.91375195, -0.91375195],\n",
       "       [-0.91375195, -0.91375194, -0.91375194, ..., -0.91375195,\n",
       "        -0.91375195, -0.91375195],\n",
       "       [-0.91375195, -0.91375194, -0.91375194, ..., -0.91375195,\n",
       "        -0.91375195, -0.91375195],\n",
       "       ..., \n",
       "       [-0.91375195, -0.91375195, -0.91375195, ..., -0.91375195,\n",
       "        -0.91375195, -0.91375195],\n",
       "       [-0.91375195, -0.91375195, -0.91375195, ..., -0.91375195,\n",
       "        -0.91375195, -0.91375195],\n",
       "       [-0.91375195, -0.91375195, -0.91375195, ..., -0.91375195,\n",
       "        -0.91375195, -0.91375195]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_predictions[0][0] # the first value is the one that must be iterated!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diff = gs_binary - prediction_matrix\n",
    "total_dim = gs_binary.shape[0] * gs_binary.shape[1]\n",
    "tpr = 1 - (diff[(diff > 0)].sum() / gs_binary.sum())\n",
    "fpr = abs(diff[(diff < 0)].sum()) / (total_dim - gs_binary.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "\nApply node that caused the error: Elemwise{sub,no_inplace}(Elemwise{Add}[(0, 0)].0, InplaceDimShuffle{x,0,1,2}.0)\nToposort index: 52\nInputs types: [TensorType(float64, (False, True, False, False)), TensorType(float64, (True, False, False, False))]\nInputs shapes: [(2680, 1, 100, 100), (1, 2680, 100, 100)]\nInputs strides: [(80000, 80000, 800, 8), (214400000, 80000, 800, 8)]\nInputs values: ['not shown', 'not shown']\nOutputs clients: [[Elemwise{sqr,no_inplace}(Elemwise{sub,no_inplace}.0), Elemwise{Composite{((i0 * i1) / i2)}}[(0, 1)](TensorConstant{(1, 1, 1, 1) of 2.0}, Elemwise{sub,no_inplace}.0, Elemwise{mul,no_inplace}.0)]]\n\nBacktrace when the node is created(use Theano flag traceback.limit=N to make it longer):\n  File \"/cellar/users/ramarty/anaconda/lib/python2.7/site-packages/IPython/kernel/zmq/kernelbase.py\", line 213, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/cellar/users/ramarty/anaconda/lib/python2.7/site-packages/IPython/kernel/zmq/kernelbase.py\", line 362, in execute_request\n    user_expressions, allow_stdin)\n  File \"/cellar/users/ramarty/anaconda/lib/python2.7/site-packages/IPython/kernel/zmq/ipkernel.py\", line 181, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/cellar/users/ramarty/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2868, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/cellar/users/ramarty/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2972, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/cellar/users/ramarty/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 3032, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-119-e01a29db5d13>\", line 3, in <module>\n    loss = lasagne.objectives.squared_error(predictions, targets)\n  File \"/cellar/users/ramarty/anaconda/lib/python2.7/site-packages/lasagne/objectives.py\", line 198, in squared_error\n    return theano.tensor.square(a - b)\n\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-121-79aeafafdd4f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'X'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;31m#if n % 10 == 0:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0my_predicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'X'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/cellar/users/ramarty/anaconda/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    869\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m                     \u001b[0mthunk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mthunk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 871\u001b[1;33m                     storage_map=getattr(self.fn, 'storage_map', None))\n\u001b[0m\u001b[0;32m    872\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m                 \u001b[1;31m# old-style linkers raise their own exceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/cellar/users/ramarty/anaconda/lib/python2.7/site-packages/theano/gof/link.pyc\u001b[0m in \u001b[0;36mraise_with_op\u001b[1;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[0;32m    312\u001b[0m         \u001b[1;31m# extra long error message in that case.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m     \u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/cellar/users/ramarty/anaconda/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: \nApply node that caused the error: Elemwise{sub,no_inplace}(Elemwise{Add}[(0, 0)].0, InplaceDimShuffle{x,0,1,2}.0)\nToposort index: 52\nInputs types: [TensorType(float64, (False, True, False, False)), TensorType(float64, (True, False, False, False))]\nInputs shapes: [(2680, 1, 100, 100), (1, 2680, 100, 100)]\nInputs strides: [(80000, 80000, 800, 8), (214400000, 80000, 800, 8)]\nInputs values: ['not shown', 'not shown']\nOutputs clients: [[Elemwise{sqr,no_inplace}(Elemwise{sub,no_inplace}.0), Elemwise{Composite{((i0 * i1) / i2)}}[(0, 1)](TensorConstant{(1, 1, 1, 1) of 2.0}, Elemwise{sub,no_inplace}.0, Elemwise{mul,no_inplace}.0)]]\n\nBacktrace when the node is created(use Theano flag traceback.limit=N to make it longer):\n  File \"/cellar/users/ramarty/anaconda/lib/python2.7/site-packages/IPython/kernel/zmq/kernelbase.py\", line 213, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/cellar/users/ramarty/anaconda/lib/python2.7/site-packages/IPython/kernel/zmq/kernelbase.py\", line 362, in execute_request\n    user_expressions, allow_stdin)\n  File \"/cellar/users/ramarty/anaconda/lib/python2.7/site-packages/IPython/kernel/zmq/ipkernel.py\", line 181, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/cellar/users/ramarty/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2868, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/cellar/users/ramarty/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2972, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/cellar/users/ramarty/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 3032, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-119-e01a29db5d13>\", line 3, in <module>\n    loss = lasagne.objectives.squared_error(predictions, targets)\n  File \"/cellar/users/ramarty/anaconda/lib/python2.7/site-packages/lasagne/objectives.py\", line 198, in squared_error\n    return theano.tensor.square(a - b)\n\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node."
     ]
    }
   ],
   "source": [
    "for n in xrange(1):\n",
    "    train(dataset['train']['X'], dataset['train']['y'])\n",
    "    #if n % 10 == 0:\n",
    "    y_predicted = get_output(dataset['test']['X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# there is an extra shape in the training that isn't in the predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[  1.68621626e+07,   1.68621626e+07,   1.68621626e+07, ...,\n",
       "           -1.52206119e+02,  -1.52206119e+02,  -1.52206119e+02],\n",
       "         [  1.68621626e+07,  -6.03771348e+07,  -6.03771348e+07, ...,\n",
       "           -1.52206119e+02,  -1.52206119e+02,  -1.52206119e+02],\n",
       "         [  1.68621626e+07,  -6.03771348e+07,  -6.03771348e+07, ...,\n",
       "           -1.60118936e+02,  -1.60118936e+02,  -1.50911294e+02],\n",
       "         ..., \n",
       "         [ -1.60118936e+02,  -1.23288369e+02,  -1.23288369e+02, ...,\n",
       "           -1.23288369e+02,  -1.23288369e+02,  -1.60118936e+02],\n",
       "         [ -1.60118936e+02,  -1.60118936e+02,  -1.23288369e+02, ...,\n",
       "           -1.23288369e+02,  -1.60118936e+02,  -1.60118936e+02],\n",
       "         [ -1.50911294e+02,  -1.60118936e+02,  -1.60118936e+02, ...,\n",
       "           -1.60118936e+02,  -1.60118936e+02,  -1.50911294e+02]]],\n",
       "\n",
       "\n",
       "       [[[  1.68621626e+07,   1.68621626e+07,   1.68621626e+07, ...,\n",
       "           -1.52206119e+02,  -1.52206119e+02,  -1.52224103e+02],\n",
       "         [  1.68621626e+07,  -6.03771348e+07,  -6.03771348e+07, ...,\n",
       "           -1.52206119e+02,  -1.52206119e+02,  -1.52224103e+02],\n",
       "         [  1.68621626e+07,  -6.03771348e+07,  -6.03771348e+07, ...,\n",
       "           -1.60118936e+02,  -1.60118936e+02,  -1.50911294e+02],\n",
       "         ..., \n",
       "         [ -1.60118936e+02,  -1.23288369e+02,  -1.23288369e+02, ...,\n",
       "           -1.23288369e+02,  -1.23288369e+02,  -1.60118936e+02],\n",
       "         [ -1.60118936e+02,  -1.60118936e+02,  -1.23288369e+02, ...,\n",
       "           -1.23288369e+02,  -1.60118936e+02,  -1.60118936e+02],\n",
       "         [ -1.50911294e+02,  -1.60118936e+02,  -1.60118936e+02, ...,\n",
       "           -1.60118936e+02,  -1.60118936e+02,  -1.50911294e+02]]],\n",
       "\n",
       "\n",
       "       [[[  1.68621626e+07,   1.68621626e+07,   1.68621626e+07, ...,\n",
       "           -1.52206119e+02,  -1.52206119e+02,  -1.52206119e+02],\n",
       "         [  1.68621626e+07,  -6.03771348e+07,  -6.03771348e+07, ...,\n",
       "           -1.52206119e+02,  -1.52206119e+02,  -1.52224103e+02],\n",
       "         [  1.68621626e+07,  -6.03771348e+07,  -6.03771348e+07, ...,\n",
       "           -1.60118936e+02,  -1.60118936e+02,  -1.50911294e+02],\n",
       "         ..., \n",
       "         [ -1.60118936e+02,  -1.23288369e+02,  -1.23288369e+02, ...,\n",
       "           -1.23288369e+02,  -1.23288369e+02,  -1.60118936e+02],\n",
       "         [ -1.60118936e+02,  -1.60118936e+02,  -1.23288369e+02, ...,\n",
       "           -1.23288369e+02,  -1.60118936e+02,  -1.60118936e+02],\n",
       "         [ -1.50911294e+02,  -1.60118936e+02,  -1.60118936e+02, ...,\n",
       "           -1.60118936e+02,  -1.60118936e+02,  -1.50911294e+02]]],\n",
       "\n",
       "\n",
       "       ..., \n",
       "       [[[  1.68621626e+07,   1.68621626e+07,   1.68621626e+07, ...,\n",
       "           -1.52206119e+02,  -1.52206119e+02,  -1.52206119e+02],\n",
       "         [  1.68621626e+07,  -6.03771348e+07,  -6.03771348e+07, ...,\n",
       "           -1.52206119e+02,  -1.52206119e+02,  -1.52224103e+02],\n",
       "         [  1.68621626e+07,  -6.03771348e+07,  -6.03771348e+07, ...,\n",
       "           -1.60118936e+02,  -1.60118936e+02,  -1.50911294e+02],\n",
       "         ..., \n",
       "         [ -1.60118936e+02,  -1.23288369e+02,  -1.23288369e+02, ...,\n",
       "           -1.23288369e+02,  -1.23288369e+02,  -1.60118936e+02],\n",
       "         [ -1.60118936e+02,  -1.60118936e+02,  -1.23288369e+02, ...,\n",
       "           -1.23288369e+02,  -1.60118936e+02,  -1.60118936e+02],\n",
       "         [ -1.50911294e+02,  -1.60118936e+02,  -1.60118936e+02, ...,\n",
       "           -1.60118936e+02,  -1.60118936e+02,  -1.50911294e+02]]],\n",
       "\n",
       "\n",
       "       [[[  1.68621626e+07,   1.68621626e+07,   1.68621626e+07, ...,\n",
       "           -1.52206119e+02,  -1.52206119e+02,  -1.52224103e+02],\n",
       "         [  1.68621626e+07,  -6.03771348e+07,  -6.03771348e+07, ...,\n",
       "           -1.52206119e+02,  -1.52206119e+02,  -1.52224103e+02],\n",
       "         [  1.68621626e+07,  -6.03771348e+07,  -6.03771348e+07, ...,\n",
       "           -1.60118936e+02,  -1.60118936e+02,  -1.50911294e+02],\n",
       "         ..., \n",
       "         [ -1.60118936e+02,  -1.23288369e+02,  -1.23288369e+02, ...,\n",
       "           -1.23288369e+02,  -1.23288369e+02,  -1.60118936e+02],\n",
       "         [ -1.60118936e+02,  -1.60118936e+02,  -1.23288369e+02, ...,\n",
       "           -1.23288369e+02,  -1.60118936e+02,  -1.60118936e+02],\n",
       "         [ -1.50911294e+02,  -1.60118936e+02,  -1.60118936e+02, ...,\n",
       "           -1.60118936e+02,  -1.60118936e+02,  -1.50911294e+02]]],\n",
       "\n",
       "\n",
       "       [[[  1.68621626e+07,   1.68621626e+07,   1.68621626e+07, ...,\n",
       "           -1.52206119e+02,  -1.52206119e+02,  -1.52206119e+02],\n",
       "         [  1.68621626e+07,  -6.03771348e+07,  -6.03771348e+07, ...,\n",
       "           -1.52206119e+02,  -1.52206119e+02,  -1.52206119e+02],\n",
       "         [  1.68621626e+07,  -6.03771348e+07,  -6.03771348e+07, ...,\n",
       "           -1.60118936e+02,  -1.60118936e+02,  -1.50911294e+02],\n",
       "         ..., \n",
       "         [ -1.60118936e+02,  -1.23288369e+02,  -1.23288369e+02, ...,\n",
       "           -1.23288369e+02,  -1.23288369e+02,  -1.60118936e+02],\n",
       "         [ -1.60118936e+02,  -1.60118936e+02,  -1.23288369e+02, ...,\n",
       "           -1.23288369e+02,  -1.60118936e+02,  -1.60118936e+02],\n",
       "         [ -1.50911294e+02,  -1.60118936e+02,  -1.60118936e+02, ...,\n",
       "           -1.60118936e+02,  -1.60118936e+02,  -1.50911294e+02]]]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test']['y'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'TensorVariable' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-84-7704bc05b7cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_predicted\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'TensorVariable' object is not callable"
     ]
    }
   ],
   "source": [
    "loss(y_predicted[0], dataset['test']['y'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.diff(y_predicted[0] == dataset['test']['y'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3300890432846720.5"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.mean_squared_error(y_predicted[0][0], dataset['test']['y'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1, 33]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-94-a2e5bb240077>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_predicted\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/cellar/users/ramarty/anaconda/lib/python2.7/site-packages/sklearn/metrics/regression.pyc\u001b[0m in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[0;32m    229\u001b[0m     \"\"\"\n\u001b[0;32m    230\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[1;32m--> 231\u001b[1;33m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[0;32m    232\u001b[0m     output_errors = np.average((y_true - y_pred) ** 2, axis=0,\n\u001b[0;32m    233\u001b[0m                                weights=sample_weight)\n",
      "\u001b[1;32m/cellar/users/ramarty/anaconda/lib/python2.7/site-packages/sklearn/metrics/regression.pyc\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \"\"\"\n\u001b[1;32m---> 74\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/cellar/users/ramarty/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 181\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1, 33]"
     ]
    }
   ],
   "source": [
    "sklearn.metrics.mean_squared_error(y_predicted[0], dataset['test']['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33, 1, 100, 100)\n"
     ]
    }
   ],
   "source": [
    "print y_predicted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33, 100, 100)\n"
     ]
    }
   ],
   "source": [
    "print dataset['test']['y'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
